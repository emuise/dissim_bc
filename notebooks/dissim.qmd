---
title: "analysis"
editor: visual
---

# setup - packages

```{r}
library(tidyverse)
library(terra)
library(tidyterra)
library(reticulate)
```

# setup - folders

```{r}
data_loc <- here::here("data")
dir.create(data_loc, showWarnings = F)
shp_loc <- here::here(data_loc, "shapefiles")
dir.create(shp_loc, showWarnings = F)
rst_loc <- here::here(data_loc, "rasters")
dir.create(rst_loc, showWarnings = F)
fig_loc <- here::here("figures")
dir.create(fig_loc, showWarnings = F)
input_loc <- here::here(data_loc, "inputs")
dir.create(input_loc, showWarnings = F)
scratch <- here::here(data_loc, "scratch")
dir.create(scratch, showWarnings = F)
```

# generate covariate quantiles

```{r}
# run if any data inputs are missing
# it doesnt fully check if everything is done so like
# source(here::here("scripts", "0_get_data.R"))

quantile_loc <- here::here(data_loc, "quantiles.csv")

if (!file.exists(quantile_loc)) {
  use_python("C:/Users/evanmuis/AppData/Local/miniconda3/envs/geo/python.exe")
  
  source_python(here::here("scripts", "0a_get_quantiles.py"))
}

quantile_df <- read_csv(quantile_loc) %>%
  pivot_wider(names_from = quantile, values_from = value) %>%
  mutate(`0` = `0` - 1e-6,
         `1` = `1` + 1e-6)
```

# load all data

```{r}
files <- list.files(input_loc, pattern = ".dat$")

nms <- tools::file_path_sans_ext(files)

all <- rast(here::here(input_loc, files))

names(all) <- nms

# correct for erroneuous data
all$elev_cv[all$elev_cv > 1000] = 1000
```

# turn covariates into bins and normalize attributes of interest

normalization is centring and scaling

```{r}
cov_names <- quantile_df %>%
  pull(variable)

binned <- map(cov_names, \(x) {
  print(x)
  rcl <- quantile_df %>%
    filter(variable == x) %>%
    select(-variable) %>%
    as.numeric()
  
  all %>%
    select(all_of(x)) %>%
    classify(rcl) %>%
    as.numeric()
}, .progress = "reclassifying bins") %>%
  rast()

names(binned) <- glue::glue("{names(binned)}_bin")
```

```{r}
attrs <- c("percentage_first_returns_above_2m",
           "total_biomass",
           "elev_cv",
           "elev_p95",
           "CumDHI",
           "VarDHI")

normed <- map(attrs, \(x) {
  print(x)
  
  all %>%
    select(all_of(x)) %>%
    scale()
}) %>%
  rast()

names(normed) <- glue::glue("{varnames(normed)}_scaled")

all_all <- c(all, binned, normed)
rm(all, binned, normed)
```

# chunk all_all and save to files

```{r}
tile_loc <- here::here(rst_loc, "tiles")
dir.create(tile_loc, showWarnings = F)

makeTiles(all_all, 
          y = 1000, 
          filename = here::here(tile_loc, "tile_.dat"),
          filetype = "envi")
```

# run incremental PCA in python
